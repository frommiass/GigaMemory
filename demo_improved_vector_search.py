#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
"""
import numpy as np
from src.submit.embeddings import (
    ImprovedEmbeddingEngine, ImprovedVectorStore, EmbeddingConfig,
    SimilarityMetric, PoolingStrategy, benchmark_performance
)


def demo_basic_usage():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    config = EmbeddingConfig(
        model_name="cointegrated/rubert-tiny2",
        batch_size=16,
        use_cache=True,
        pooling_strategy=PoolingStrategy.MEAN
    )
    
    engine = ImprovedEmbeddingEngine(config)
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    store = ImprovedVectorStore(
        metric=SimilarityMetric.COSINE,
        enable_analytics=True
    )
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    documents = [
        "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑–æ–≤",
        "–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö",
        "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞",
        "BERT - —ç—Ç–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
        "GPT –º–æ–¥–µ–ª–∏ —Å–ø–æ—Å–æ–±–Ω—ã –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç",
        "–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ NLP",
        "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤–æ–º –≤–∏–¥–µ"
    ]
    
    print(f"üìö –î–æ–±–∞–≤–ª—è–µ–º {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    
    # –ö–æ–¥–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    embeddings = engine.encode(documents, show_progress=True)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    for i, (doc, embedding) in enumerate(zip(documents, embeddings)):
        store.add(
            doc_id=f"doc_{i}",
            vector=embedding,
            metadata={"category": "AI", "index": i},
            text=doc
        )
    
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    query = "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏?"
    print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
    
    query_embedding = engine.encode(query)
    results = store.search(query_embedding, k=3)
    
    print("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:")
    for i, result in enumerate(results, 1):
        print(f"  {i}. {result.doc_id}: {result.score:.3f}")
        print(f"     –¢–µ–∫—Å—Ç: {result.text}")
        print(f"     –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.metadata}")
        print()
    
    # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
    print("üîç –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π + —Ç–µ–∫—Å—Ç–æ–≤—ã–π):")
    hybrid_results = store.hybrid_search(
        query_embedding, 
        query,
        k=3,
        vector_weight=0.7,
        text_weight=0.3
    )
    
    print("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
    for i, result in enumerate(hybrid_results, 1):
        print(f"  {i}. {result.doc_id}: {result.score:.3f}")
        print(f"     –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {result.explanation}")
        print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–≤–∏–∂–∫–∞:")
    engine_stats = engine.get_stats()
    for key, value in engine_stats.items():
        print(f"  {key}: {value}")
    
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞:")
    store_stats = store.get_analytics()
    print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {store_stats.total_documents}")
    print(f"  –í—Å–µ–≥–æ –ø–æ–∏—Å–∫–æ–≤: {store_stats.total_searches}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {store_stats.avg_search_time:.3f} —Å–µ–∫")


def demo_advanced_features():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
    print("\nüöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    config = EmbeddingConfig(
        model_name="cointegrated/rubert-tiny2",
        batch_size=32,
        use_cache=True,
        use_amp=True,
        pooling_strategy=PoolingStrategy.WEIGHTED_MEAN,
        warmup_steps=2
    )
    
    engine = ImprovedEmbeddingEngine(config)
    
    # –°–æ–∑–¥–∞–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    stores = {
        "cosine": ImprovedVectorStore(metric=SimilarityMetric.COSINE),
        "euclidean": ImprovedVectorStore(metric=SimilarityMetric.EUCLIDEAN),
        "angular": ImprovedVectorStore(metric=SimilarityMetric.ANGULAR)
    }
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    texts = [
        "–ö–æ—Ç —Å–∏–¥–∏—Ç –Ω–∞ –∫–æ–≤—Ä–∏–∫–µ",
        "–°–æ–±–∞–∫–∞ –∏–≥—Ä–∞–µ—Ç –≤–æ –¥–≤–æ—Ä–µ", 
        "–ü—Ç–∏—Ü–∞ –ø–æ–µ—Ç –Ω–∞ –¥–µ—Ä–µ–≤–µ",
        "–†—ã–±–∞ –ø–ª–∞–≤–∞–µ—Ç –≤ –∞–∫–≤–∞—Ä–∏—É–º–µ",
        "–õ–æ—à–∞–¥—å –±–µ–≥–∞–µ—Ç –ø–æ –ø–æ–ª—é"
    ]
    
    embeddings = engine.encode(texts)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–∞–∑–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    for metric_name, store in stores.items():
        for i, (text, embedding) in enumerate(zip(texts, embeddings)):
            store.add(
                doc_id=f"{metric_name}_doc_{i}",
                vector=embedding,
                metadata={"animal": text.split()[0]},
                text=text
            )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    query = "–¥–æ–º–∞—à–Ω–∏–µ –∂–∏–≤–æ—Ç–Ω—ã–µ"
    query_embedding = engine.encode(query)
    
    print(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Å—Ö–æ–¥—Å—Ç–≤–∞:")
    
    for metric_name, store in stores.items():
        results = store.search(query_embedding, k=3)
        print(f"\nüìä {metric_name.upper()} –º–µ—Ç—Ä–∏–∫–∞:")
        for result in results:
            print(f"  - {result.doc_id}: {result.score:.3f} ({result.text})")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
    print(f"\nüîç –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º:")
    cosine_store = stores["cosine"]
    
    # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –∂–∏–≤–æ—Ç–Ω—ã–º
    filtered_results = cosine_store.search(
        query_embedding, 
        k=5,
        filter_metadata={"animal": "–ö–æ—Ç"}
    )
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–æ–º 'animal: –ö–æ—Ç':")
    for result in filtered_results:
        print(f"  - {result.doc_id}: {result.score:.3f}")
    
    # –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\nüîç –ü–æ–∏—Å–∫ —Å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º:")
    reranked_results = cosine_store.search(
        query_embedding,
        k=5,
        rerank=True,
        return_explanations=True
    )
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º:")
    for result in reranked_results:
        print(f"  - {result.doc_id}: {result.score:.3f}")
        if result.explanation:
            print(f"    –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {result.explanation}")


def demo_performance():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("\n‚ö° –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 50)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
    metrics = benchmark_performance(
        n_documents=500,
        batch_size=32,
        k=10,
        enable_amp=True,
        use_cache=True
    )
    
    print(f"\nüèÜ –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
    print(f"  –°–∫–æ—Ä–æ—Å—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {metrics.encoding_speed:.0f} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—Å–µ–∫")
    print(f"  –°–∫–æ—Ä–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞: {metrics.search_speed:.0f} –ø–æ–∏—Å–∫–æ–≤/—Å–µ–∫")
    print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏: {metrics.memory_efficiency:.0f} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/–ú–ë")
    print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫—ç—à–∞: {metrics.cache_efficiency:.1%}")
    print(f"  P95 –∑–∞–¥–µ—Ä–∂–∫–∞: {metrics.latency_p95:.1f} –º—Å")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("=" * 60)
    
    try:
        # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
        demo_basic_usage()
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        demo_advanced_features()
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        demo_performance()
        
        print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
