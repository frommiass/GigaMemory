#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã GigaMemory —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø—Ä–æ–º–ø—Ç–æ–≤
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from models import Message
import logging
import time
from typing import List, Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GigaMemoryDemo:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã GigaMemory"""
    
    def __init__(self):
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ GigaMemory")
        print("=" * 60)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.embedding_engine = MockEmbeddingEngine()
        self.vector_store = MockVectorStore()
        self.fact_extractor = MockFactExtractor()
        self.compressor = MockCompressor()
        self.prompt_generator = AdvancedPromptGenerator()
        
        # –ë–∞–∑–∞ —Ñ–∞–∫—Ç–æ–≤
        self.fact_database = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'dialogues_processed': 0,
            'total_facts_extracted': 0,
            'total_queries': 0,
            'avg_compression_ratio': 0.0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def process_dialogue(self, dialogue_id: str, messages: List[Message]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ª–æ–≥ –ø–æ–ª–Ω—ã–º —Ü–∏–∫–ª–æ–º"""
        print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞: {dialogue_id}")
        print("-" * 40)
        
        start_time = time.time()
        
        # 1. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–µ—Å—Å–∏—è–º
        sessions = self._group_messages_by_sessions(messages)
        print(f"üìä –°–æ–∑–¥–∞–Ω–æ —Å–µ—Å—Å–∏–π: {len(sessions)}")
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π —Å–µ—Å—Å–∏–∏
        total_facts = 0
        compression_ratios = []
        
        for session_id, session_messages in sessions.items():
            print(f"\nüìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Å—Å–∏–∏: {session_id}")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏
            session_text = " ".join([msg.content for msg in session_messages])
            print(f"   –¢–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏: {session_text[:100]}...")
            
            # –°–∂–∞—Ç–∏–µ
            compression_result = self.compressor.compress(session_text)
            compression_ratios.append(compression_result['compression_ratio'])
            print(f"   –°–∂–∞—Ç–∏–µ: {compression_result['compression_ratio']:.2f}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            embedding = self.embedding_engine.encode([session_text])[0]
            print(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω: {len(embedding)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
            facts = self.fact_extractor.extract_facts_from_text(session_text, session_id, dialogue_id)
            total_facts += len(facts)
            print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {len(facts)}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            self.vector_store.add_documents([session_text], [embedding])
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
            if dialogue_id not in self.fact_database:
                self.fact_database[dialogue_id] = []
            self.fact_database[dialogue_id].extend(facts)
        
        # 3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        processing_time = time.time() - start_time
        avg_compression = sum(compression_ratios) / len(compression_ratios) if compression_ratios else 1.0
        
        self.stats['dialogues_processed'] += 1
        self.stats['total_facts_extracted'] += total_facts
        self.stats['avg_compression_ratio'] = avg_compression
        
        result = {
            'dialogue_id': dialogue_id,
            'sessions_count': len(sessions),
            'facts_extracted': total_facts,
            'compression_ratio': avg_compression,
            'processing_time': processing_time,
            'documents_indexed': len(sessions)
        }
        
        print(f"\n‚úÖ –î–∏–∞–ª–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time:.3f}—Å")
        return result
    
    def answer_question(self, dialogue_id: str, question: str) -> str:
        """–û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å—é —Å–∏—Å—Ç–µ–º—É"""
        print(f"\n‚ùì –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞: {question}")
        print("-" * 40)
        
        start_time = time.time()
        
        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        query_embedding = self.embedding_engine.encode([question])[0]
        similar_docs = self.vector_store.search(query_embedding, top_k=3)
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(similar_docs)}")
        for i, doc in enumerate(similar_docs, 1):
            print(f"   {i}. –°—Ö–æ–∂–µ—Å—Ç—å: {doc['similarity']:.3f}")
            print(f"      –¢–µ–∫—Å—Ç: {doc['document'][:80]}...")
        
        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
        relevant_facts = self.fact_database.get(dialogue_id, [])
        print(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {len(relevant_facts)}")
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞
        memory_data = [doc['document'] for doc in similar_docs]
        prompt = self.prompt_generator.generate_enhanced_prompt(question, memory_data)
        
        print(f"\nüìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç:")
        print("=" * 50)
        print(prompt)
        print("=" * 50)
        
        # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (–º–æ–∫)
        answer = self._generate_mock_answer(question, similar_docs, relevant_facts)
        
        # 5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        query_time = time.time() - start_time
        self.stats['total_queries'] += 1
        
        print(f"\nü§ñ –û—Ç–≤–µ—Ç: {answer}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {query_time:.3f}—Å")
        
        return answer
    
    def _group_messages_by_sessions(self, messages: List[Message]) -> Dict[str, List[Message]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Å–µ—Å—Å–∏—è–º"""
        sessions = {}
        current_session = "session_1"
        
        for msg in messages:
            if current_session not in sessions:
                sessions[current_session] = []
            sessions[current_session].append(msg)
        
        return sessions
    
    def _generate_mock_answer(self, question: str, similar_docs: List[Dict], facts: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–∫-–æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        question_lower = question.lower()
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if "—Ä–∞–±–æ—Ç–∞" in question_lower:
            return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º –≤ –∫–æ–º–ø–∞–Ω–∏–∏ –Ø–Ω–¥–µ–∫—Å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ Python –∏ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏."
        elif "—Å–µ–º—å—è" in question_lower:
            return "–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å—Ç—å –∂–µ–Ω–∞ –ú–∞—Ä–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç —É—á–∏—Ç–µ–ª–µ–º –≤ —à–∫–æ–ª–µ, –∏ –¥–æ—á—å –ê–Ω–Ω–∞ 5 –ª–µ—Ç."
        elif "–∂–∏–≤–µ—Ç" in question_lower:
            return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–∏–≤–µ—Ç –≤ –ú–æ—Å–∫–≤–µ, –≤ —Ä–∞–π–æ–Ω–µ –°–æ–∫–æ–ª—å–Ω–∏–∫–∏, —Ä–∞–±–æ—Ç–∞–µ—Ç —É–¥–∞–ª–µ–Ω–Ω–æ."
        elif "—É–≤–ª–µ—á–µ–Ω–∏—è" in question_lower:
            return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–≤–ª–µ–∫–∞–µ—Ç—Å—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π –∏ —á–∞—Å—Ç–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–µ—Ç —Å–µ–º—å—é –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö."
        elif "–∂–∏–≤–æ—Ç–Ω—ã–µ" in question_lower:
            return "–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å—Ç—å —Å–æ–±–∞–∫–∞ –ø–æ –∫–ª–∏—á–∫–µ –†–µ–∫—Å, –∫–æ—Ç–æ—Ä–∞—è –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω–∞—è."
        elif "–∏–∑—É—á–∞–µ—Ç" in question_lower:
            return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑—É—á–∞–µ—Ç Python, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –Ω–µ–¥–∞–≤–Ω–æ –Ω–∞—á–∞–ª –∏–∑—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."
        elif "–∂–µ–Ω–∞" in question_lower:
            return "–ñ–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ú–∞—Ä–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç —É—á–∏—Ç–µ–ª–µ–º –≤ —à–∫–æ–ª–µ –∏ –æ—á–µ–Ω—å –ª—é–±–∏—Ç —Å–≤–æ—é —Ä–∞–±–æ—Ç—É."
        elif "–¥–æ—á—å" in question_lower:
            return "–î–æ—á–µ—Ä–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ê–Ω–Ω–µ 5 –ª–µ—Ç, –æ–Ω–∞ —Ö–æ–¥–∏—Ç –≤ –¥–µ—Ç—Å–∫–∏–π —Å–∞–¥ –∏ –ª—é–±–∏—Ç —Ä–∏—Å–æ–≤–∞—Ç—å."
        else:
            return "–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –æ —Ä–∞–±–æ—Ç–µ, —Å–µ–º—å–µ, –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ –∏ —É–≤–ª–µ—á–µ–Ω–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
    
    def get_system_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã"""
        return {
            'processing': self.stats,
            'storage': {
                'total_documents': len(self.vector_store.documents),
                'total_facts': sum(len(facts) for facts in self.fact_database.values()),
                'dialogues_count': len(self.fact_database)
            },
            'performance': {
                'avg_query_time': 0.15,  # –ú–æ–∫-–∑–Ω–∞—á–µ–Ω–∏–µ
                'cache_hit_rate': 0.85,   # –ú–æ–∫-–∑–Ω–∞—á–µ–Ω–∏–µ
                'compression_efficiency': self.stats['avg_compression_ratio']
            }
        }

class MockEmbeddingEngine:
    """–ú–æ–∫-–≤–µ—Ä—Å–∏—è EmbeddingEngine"""
    
    def encode(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for text in texts:
            hash_val = hash(text) % 1000
            embedding = [hash_val / 1000.0] * 384
            embeddings.append(embedding)
        return embeddings

class MockVectorStore:
    """–ú–æ–∫-–≤–µ—Ä—Å–∏—è VectorStore"""
    
    def __init__(self):
        self.documents = {}
        self.embeddings = {}
    
    def add_documents(self, documents: List[str], embeddings: List[List[float]]):
        for i, (doc, emb) in enumerate(zip(documents, embeddings)):
            doc_id = f"doc_{len(self.documents)}"
            self.documents[doc_id] = doc
            self.embeddings[doc_id] = emb
    
    def search(self, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
        results = []
        for doc_id, emb in self.embeddings.items():
            similarity = sum(a * b for a, b in zip(query_embedding, emb)) / len(emb)
            results.append({
                'document': self.documents[doc_id],
                'similarity': similarity,
                'metadata': {'doc_id': doc_id}
            })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:top_k]

class MockFactExtractor:
    """–ú–æ–∫-–≤–µ—Ä—Å–∏—è FactExtractor"""
    
    def extract_facts_from_text(self, text: str, session_id: str, dialogue_id: str) -> List[Dict]:
        facts = []
        text_lower = text.lower()
        
        if "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç" in text_lower:
            facts.append({'type': 'work', 'content': '–†–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º', 'confidence': 0.9})
        if "—è–Ω–¥–µ–∫—Å" in text_lower:
            facts.append({'type': 'work', 'content': '–†–∞–±–æ—Ç–∞–µ—Ç –≤ –Ø–Ω–¥–µ–∫—Å', 'confidence': 0.8})
        if "–∂–µ–Ω–∞" in text_lower:
            facts.append({'type': 'family', 'content': '–ï—Å—Ç—å –∂–µ–Ω–∞', 'confidence': 0.9})
        if "–¥–æ—á—å" in text_lower:
            facts.append({'type': 'family', 'content': '–ï—Å—Ç—å –¥–æ—á—å', 'confidence': 0.9})
        if "–º–æ—Å–∫–≤–∞" in text_lower:
            facts.append({'type': 'location', 'content': '–ñ–∏–≤–µ—Ç –≤ –ú–æ—Å–∫–≤–µ', 'confidence': 0.8})
        if "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π" in text_lower:
            facts.append({'type': 'hobby', 'content': '–£–≤–ª–µ–∫–∞–µ—Ç—Å—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π', 'confidence': 0.7})
        if "—Å–æ–±–∞–∫–∞" in text_lower:
            facts.append({'type': 'pets', 'content': '–ï—Å—Ç—å —Å–æ–±–∞–∫–∞', 'confidence': 0.8})
        
        return facts

class MockCompressor:
    """–ú–æ–∫-–≤–µ—Ä—Å–∏—è Compressor"""
    
    def compress(self, text: str) -> Dict[str, Any]:
        compressed = text[:100] + "..." if len(text) > 100 else text
        ratio = len(compressed) / len(text) if len(text) > 0 else 1.0
        
        return {
            'compressed_text': compressed,
            'compression_ratio': ratio,
            'original_length': len(text),
            'compressed_length': len(compressed)
        }

class AdvancedPromptGenerator:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤"""
    
    def __init__(self):
        self.fact_categories = {
            'work': ['–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', '—Ä–∞–±–æ—Ç–∞', '–∫–æ–º–ø–∞–Ω–∏—è', '—è–Ω–¥–µ–∫—Å', 'python'],
            'family': ['–∂–µ–Ω–∞', '–¥–æ—á—å', '—Å–µ–º—å—è', '–º–∞—Ä–∏—è', '–∞–Ω–Ω–∞'],
            'location': ['–º–æ—Å–∫–≤–∞', '–∂–∏–≤–µ—Ç', '—Å–æ–∫–æ–ª—å–Ω–∏–∫–∏'],
            'hobby': ['—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π', '—É–≤–ª–µ–∫–∞–µ—Ç—Å—è'],
            'pets': ['—Å–æ–±–∞–∫–∞', '—Ä–µ–∫—Å'],
            'education': ['–∏–∑—É—á–∞–µ—Ç', '–Ω–µ–π—Ä–æ—Å–µ—Ç–∏']
        }
    
    def classify_question(self, question: str) -> str:
        question_lower = question.lower()
        for category, keywords in self.fact_categories.items():
            if any(keyword in question_lower for keyword in keywords):
                return category
        return 'general'
    
    def extract_context_from_memory(self, memory_data: List[str], question: str) -> str:
        question_lower = question.lower()
        relevant_contexts = []
        
        for memory_item in memory_data:
            memory_lower = memory_item.lower()
            question_words = set(question_lower.split())
            memory_words = set(memory_lower.split())
            
            if question_words.intersection(memory_words):
                relevant_contexts.append(memory_item)
        
        return "\n".join(relevant_contexts[:3])
    
    def generate_enhanced_prompt(self, question: str, memory_data: List[str]) -> str:
        category = self.classify_question(question)
        context = self.extract_context_from_memory(memory_data, question)
        
        prompt_parts = [
            "–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.",
            "–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å:",
            "",
            "–í–û–ü–†–û–°: " + question,
            ""
        ]
        
        if context:
            prompt_parts.extend([
                "–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ü–ê–ú–Ø–¢–ò:",
                context,
                ""
            ])
        
        prompt_parts.extend([
            "–ò–ù–°–¢–†–£–ö–¶–ò–ò:",
            "- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É",
            "- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
            "- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º",
            "- –ë—É–¥—å —Ç–æ—á–Ω—ã–º –≤ –¥–µ—Ç–∞–ª—è—Ö"
        ])
        
        return "\n".join(prompt_parts)

def run_full_demo():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã"""
    
    print("üéØ –ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã GigaMemory")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    system = GigaMemoryDemo()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_messages = [
        Message(role="user", content="–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π, —è —Ä–∞–±–æ—Ç–∞—é –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º –≤ –∫–æ–º–ø–∞–Ω–∏–∏ –Ø–Ω–¥–µ–∫—Å."),
        Message(role="user", content="–£ –º–µ–Ω—è –µ—Å—Ç—å –∂–µ–Ω–∞ –ú–∞—Ä–∏—è –∏ –¥–æ—á—å –ê–Ω–Ω–∞, –∫–æ—Ç–æ—Ä–æ–π 5 –ª–µ—Ç."),
        Message(role="user", content="–Ø –∂–∏–≤—É –≤ –ú–æ—Å–∫–≤–µ, –≤ —Ä–∞–π–æ–Ω–µ –°–æ–∫–æ–ª—å–Ω–∏–∫–∏. –†–∞–±–æ—Ç–∞—é —É–¥–∞–ª–µ–Ω–Ω–æ."),
        Message(role="user", content="–ú–æ—è –∂–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —É—á–∏—Ç–µ–ª–µ–º –≤ —à–∫–æ–ª–µ. –û–Ω–∞ –æ—á–µ–Ω—å –ª—é–±–∏—Ç —Å–≤–æ—é —Ä–∞–±–æ—Ç—É."),
        Message(role="user", content="–£ –Ω–∞—Å –µ—Å—Ç—å —Å–æ–±–∞–∫–∞ –ø–æ –∫–ª–∏—á–∫–µ –†–µ–∫—Å. –û–Ω –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π."),
        Message(role="user", content="–Ø —É–≤–ª–µ–∫–∞—é—Å—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π –∏ —á–∞—Å—Ç–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É—é —Å–µ–º—å—é –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö."),
        Message(role="user", content="–ù–∞—à–∞ –¥–æ—á—å —Ö–æ–¥–∏—Ç –≤ –¥–µ—Ç—Å–∫–∏–π —Å–∞–¥ –∏ –æ—á–µ–Ω—å –ª—é–±–∏—Ç —Ä–∏—Å–æ–≤–∞—Ç—å."),
        Message(role="user", content="–Ø —Ä–∞–±–æ—Ç–∞—é —Å Python –∏ –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. –ù–µ–¥–∞–≤–Ω–æ –∏–∑—É—á–∞—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."),
    ]
    
    dialogue_id = "demo_dialogue_1"
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞
    print(f"\nüìö –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞: {dialogue_id}")
    stats = system.process_dialogue(dialogue_id, test_messages)
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Ä–∞–±–æ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
        "–ö–∞–∫–∞—è —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–º—å—è?",
        "–ì–¥–µ –∂–∏–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å?",
        "–ö–∞–∫–∏–µ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —É–≤–ª–µ—á–µ–Ω–∏—è?",
        "–†–∞—Å—Å–∫–∞–∂–∏ –æ –¥–æ–º–∞—à–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö",
        "–ß—Ç–æ –∏–∑—É—á–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å?"
    ]
    
    # –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
    print(f"\n‚ùì –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã:")
    print("=" * 60)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{i}. {question}")
        answer = system.answer_question(dialogue_id, question)
        print(f"   –û—Ç–≤–µ—Ç: {answer}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìà –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã:")
    print("=" * 60)
    
    final_stats = system.get_system_stats()
    for category, stats in final_stats.items():
        print(f"\n{category.upper()}:")
        for key, value in stats.items():
            if isinstance(value, dict):
                print(f"  {key}:")
                for sub_key, sub_value in value.items():
                    print(f"    {sub_key}: {sub_value}")
            else:
                print(f"  {key}: {value}")
    
    print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"‚úÖ –ü–æ–∫–∞–∑–∞–Ω–∞ –ø–æ–ª–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å–∏—Å—Ç–µ–º—ã GigaMemory")
    print(f"‚úÖ –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤")
    print(f"‚úÖ –ü–æ–∫–∞–∑–∞–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")

if __name__ == "__main__":
    run_full_demo()
