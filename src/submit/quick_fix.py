#!/usr/bin/env python3
"""
Quick fix script - Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ²ÑĞµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
Ğ—Ğ°Ğ¿ÑƒÑĞº: python src/submit/quick_fix.py
"""

import os
import sys
import shutil
from pathlib import Path

def backup_file(filepath):
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½ÑƒÑ ĞºĞ¾Ğ¿Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    backup_path = f"{filepath}.backup"
    if not os.path.exists(backup_path):
        shutil.copy2(filepath, backup_path)
        print(f"âœ… Backup created: {backup_path}")

def apply_fix_embeddings():
    """Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ EmbeddingsModule"""
    print("\nğŸ”§ Fixing EmbeddingsModule...")
    
    filepath = "src/submit/modules/embeddings/module.py"
    
    try:
        with open(filepath, 'r') as f:
            content = f.read()
        
        # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ set_optimizer Ğ½Ğ° set_dependencies
        if "def set_optimizer(" in content:
            content = content.replace(
                "def set_optimizer(self, optimizer):",
                "def set_dependencies(self, optimizer=None, storage=None, embeddings=None):"
            )
            print("  âœ… Replaced set_optimizer -> set_dependencies")
        
        with open(filepath, 'w') as f:
            f.write(content)
        
        print("âœ… EmbeddingsModule fixed!")
        return True
        
    except Exception as e:
        print(f"âŒ Error fixing EmbeddingsModule: {e}")
        return False

def apply_fix_compression():
    """Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ CompressionModule"""
    print("\nğŸ”§ Fixing CompressionModule...")
    
    filepath = "src/submit/modules/compression/module.py"
    
    try:
        with open(filepath, 'r') as f:
            content = f.read()
        
        # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ set_optimizer Ğ½Ğ° set_dependencies
        if "def set_optimizer(" in content:
            content = content.replace(
                "def set_optimizer(self, optimizer):",
                "def set_dependencies(self, optimizer=None):"
            )
            print("  âœ… Replaced set_optimizer -> set_dependencies")
        
        with open(filepath, 'w') as f:
            f.write(content)
        
        print("âœ… CompressionModule fixed!")
        return True
        
    except Exception as e:
        print(f"âŒ Error fixing CompressionModule: {e}")
        return False

def apply_fix_llm_inference():
    """Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ModelInference"""
    print("\nğŸ”§ Fixing ModelInference...")
    
    filepath = "src/submit/llm_inference.py"
    
    try:
        with open(filepath, 'r') as f:
            content = f.read()
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚
        if "from core.interfaces import IModelInference" not in content:
            import_line = "from core.interfaces import IModelInference, ProcessingResult\n"
            content = import_line + content
            print("  âœ… Added interface imports")
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°
        if "class ModelInference:" in content and "IModelInference" not in content:
            content = content.replace(
                "class ModelInference:",
                "class ModelInference(IModelInference):"
            )
            print("  âœ… Added interface inheritance")
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´ generate ĞµÑĞ»Ğ¸ ĞµĞ³Ğ¾ Ğ½ĞµÑ‚
        if "def generate(self, messages: List[Message]) -> ProcessingResult:" not in content:
            generate_method = '''
    def generate(self, messages: List[Message]) -> ProcessingResult:
        """Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ° IModelInference"""
        try:
            result = self.inference(messages)
            return ProcessingResult(
                success=True,
                data=result,
                metadata={
                    'model_path': self.model_path,
                    'messages_count': len(messages)
                }
            )
        except Exception as e:
            return ProcessingResult(
                success=False,
                data="ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.",
                metadata={'error': str(e)},
                error=str(e)
            )
'''
            # Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»Ğµ __init__
            insert_pos = content.find("def inference(")
            if insert_pos > 0:
                content = content[:insert_pos] + generate_method + "\n" + content[insert_pos:]
                print("  âœ… Added generate method")
        
        with open(filepath, 'w') as f:
            f.write(content)
        
        print("âœ… ModelInference fixed!")
        return True
        
    except Exception as e:
        print(f"âŒ Error fixing ModelInference: {e}")
        return False

def apply_fix_orchestrator():
    """Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Orchestrator"""
    print("\nğŸ”§ Fixing Orchestrator...")
    
    filepath = "src/submit/core/orchestrator.py"
    
    try:
        with open(filepath, 'r') as f:
            content = f.read()
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ RAG Ğ² _setup_dependencies ĞµÑĞ»Ğ¸ ĞµĞ³Ğ¾ Ğ½ĞµÑ‚
        if "self.rag.set_dependencies" not in content:
            rag_setup = '''
    # RAG Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²ÑĞµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸
    if hasattr(self.rag, 'set_dependencies'):
        self.rag.set_dependencies(
            storage=self.storage,
            embeddings=self.embeddings,
            extractor=self.extractor,
            compressor=self.compressor,
            optimizer=self.optimizer
        )'''
            
            # Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ´ logger.info
            insert_pos = content.find('logger.info("Module dependencies configured")')
            if insert_pos > 0:
                content = content[:insert_pos] + rag_setup + "\n\n    " + content[insert_pos:]
                print("  âœ… Added RAG dependencies setup")
        
        with open(filepath, 'w') as f:
            f.write(content)
        
        print("âœ… Orchestrator fixed!")
        return True
        
    except Exception as e:
        print(f"âŒ Error fixing Orchestrator: {e}")
        return False

def main():
    print("="*50)
    print("ğŸš€ GIGAMEMORY QUICK FIX")
    print("="*50)
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ„Ğ¸ĞºÑÑ‹
    results = []
    
    results.append(("EmbeddingsModule", apply_fix_embeddings()))
    results.append(("CompressionModule", apply_fix_compression()))
    results.append(("ModelInference", apply_fix_llm_inference()))
    results.append(("Orchestrator", apply_fix_orchestrator()))
    
    # ĞÑ‚Ñ‡ĞµÑ‚
    print("\n" + "="*50)
    print("ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«:")
    print("="*50)
    
    for module, success in results:
        status = "âœ… FIXED" if success else "âŒ FAILED"
        print(f"{module:.<30} {status}")
    
    if all(success for _, success in results):
        print("\nâœ… Ğ’ÑĞµ Ñ„Ğ¸ĞºÑÑ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ñ‹ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
        print("Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ: python src/submit/final_integration.py")
    else:
        print("\nâš ï¸ ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ„Ğ¸ĞºÑÑ‹ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ")

if __name__ == "__main__":
    main()
