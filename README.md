# GigaMemory: global memory for LLM
## Содержание
- [Oписание задачи](#oписание-задачи)
- [Описание формата решения](#описание-формата-решения)
- [Данные](#данные)
- [Подсчёт метрики](#подсчёт-метрики)
- [Ограничения](#ограничения)
- [Baseline решение](#baseline-решение)
- [Призовой фонд](#призовой-фонд)

## Oписание задачи
Большие языковые модели (Large Language Model (LLM)) являются горячей темой для исследований и разработки в последние годы. Однако до сих пор LLM, при всей своей мощности, сталкиваются с большой проблемой - у них слабо развита память. При общении с пользователем модель на следующий день забывает даже базовую информацию о человеке - его имя, возраст и т.п. Это значительно ухудшает пользовательский опыт и ограничивает возможности применения LLM в различных прикладных задачах. Однако за последний год появились первые успехи в развитии этого направления, что даёт мощный импульс для исследований памяти LLM. Каким образом запоминать данные? Как и в каком формате хранить запомненную информацию? Как использовать выделенные данные во время генерации ответа LLM? В рамках данного соревнования участникам предлагается ответить на эти и многие другие прикладные вопросы разработки модуля памяти.

### Постановка задачи

Суть задачи - создать глобальную память для LLM в виде независимого модуля. Под глобальной памятью понимается свойство выделять и запоминать атомарные факты о пользователе, содержащие любую информацию, которая может пригодиться при дальнейших взаимодействиях с пользователем.

Для реализации модуля памяти допускается использование любой технологии в рамках ограничений конкурса. Формат и тип данных, в которых хранится память, произвольные.

Проверка качества работы модуля памяти будет проводиться на диалоговом датасете: валидационной и тестовой части. До завершения приёма решений будет использоваться только валидационная часть, на основании которой считается публичный лидерборд; после - тестовая, которая, в свою очередь, формирует приватный лидерборд. Обе части датасета - закрытые.

Принцип проверки модуля памяти для каждого диалога следующий: диалог будет разбит на пары пользовательская реплика – ответ ассистента. Метод записи в память последовательно вызывается на новых парах диалога и должен сохранять в себе информацию о пользователе. Таким образом для каждого диалога производится n/2 вызовов памяти, где n – длина диалога. Модуль памяти формирует память произвольного формата и типа данных.
После прохода по всему диалогу, осуществляется вызов метода ответа ассистента на тестовый вопрос с использованием памяти. Ответить на вопрос должна модель [GigaChat Lite](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct-v1.5-bf16), инструкцию для которой участник формирует самостоятельно. Ожидается, что в инструкции будет содержаться объект памяти, вопрос и все необходимые инструкции по ответу. 
Полученный ответ подаётся для оценки соответствия правильному ответу с помощью «LLM as a judge».


## Описание формата решения
В проверяющую систему необходимо отправить код, запакованный в ZIP-архив. 
Решения запускаются в изолированном окружении при помощи Docker. Время и ресурсы во время тестирования ограничены (см. [Раздел “Ограничения”](#ограничения)).

Пример посылаемого решения (baseline) можно найти в репозитории в директории [src/submit](https://gitverse.ru/ai-forever/memory_aij2025/content/main/src/submit). 
Для создания тестового submit необходимо запаковать содержимое этой директории в ZIP-архив и отправить в проверяющую систему.


Для локального запуска решений Вы можете воспроизвести существующее окружение. Dockerfile и requirements.txt для данного образа приведены в репозитории.

Важные моменты при формировании решения: 

* Все необходимые библиотеки, которых нет в базовом образе, предлагается загружать в архиве решения и устанавливать из кода (с учётом совместимости с библиотеками внутри базового образа) 
* Веса моделей небольшого размера, которые удовлетворяют суммарному ограничению по объёму решения в 5 Гб, могут загружаться в самом решении.
* Вариант базовой модели [GigaChat Lite](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct-v1.5-bf16), на которой предполагается построение решения, уже помещён в базовый образ по пути /app/models
 
Структура кода самого решения чётко не регламентирована. Необходимо только, чтобы в корне решения присутствовали:
-  скрипт model_inference.py с реализацией класса SubmitModelWithMemory, который будет соответствовать сигнатуре абстрактного класса [ModelWithMemory](https://gitverse.ru/ai-forever/memory_aij2025/content/main/src/submit_interface.py) с реализацией всех необходимых методов из неё:
```python
class ModelWithMemory(ABC):

   @abstractmethod
   def write_to_memory(self, messages: List[Message], dialogue_id: str) -> None:
       # записать в память
       pass

   @abstractmethod
   def clear_memory(self, dialogue_id: str) -> None:
       # очистить память
       pass

   @abstractmethod
   def answer_to_question(self, dialogue_id: str, question: str) -> str:
       # получить ответ на вопрос при помощи GigaChat Lite
       pass
```
- скрипт \_\_init\_\_.py c импортом данного класса

Допускается добавление других файлов и кода, необходимых для реализации решения. Не допускается изменение остальных классов и методов кода организаторов.
Пример корректной реализации класса и методов можно посмотреть в Baseline решении.	


Чтобы локально проверить правильность вашего решения, предлагается выполнить следующие шаги:

1. Склонировать репозиторий соревнования и перейти в корневую директорию 
2. Склонировать к себе базовую модель:
```
git lfs install 
git clone https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct-v1.5-bf16
```
2.1. Убедитесь что модель загружена в директорию GigaChat-20B-A3B-instruct-v1.5-bf16 (файлы занимают в сумме ~40 Гб)
```
cd GigaChat-20B-A3B-instruct-v1.5-bf16
ls -lha
cd ..
```
2.2. В случае некорректной загрузки:
```
cd GigaChat-20B-A3B-instruct-v1.5-bf16
git lfs pull
cd ..
```
3. Создать окружение:
```
conda create -n my_env python=3.10 -y
```
4. Активировать окружение:
```
conda activate my_env
```
5. Установить необходимый минимум зависимостей:
```
pip install -r requirements.txt
```
6. Точка входа для запуска бейзлайна - файл src/run.py. Для корректного запуска нужно прописать в стартовом методе (строчки 165-170) следующие пути:
    - dataset_path - путь до датасета, по которому будут расчитываться предсказания модели. Образец датасета [выложен](https://gitverse.ru/ai-forever/memory_aij2025/content/main/data/format_example.jsonl) в репозитории, для запуска с ним следует прописать путь `../data/format_example.jsonl`
    - output_path - путь до директории, в которую будут сохранены результаты работы модели. В случае отсутствия директории, она будет создана автоматически.
    - model_path - путь до директории, в которой лежит модель GigaChat Lite.

Пример кода с относительными путями:
```python
if __name__ == "__main__":
    launch_inference_and_check_errors(
        dataset_path="../data/format_example.jsonl",
        output_path="../output",
        model_path="../GigaChat-20B-A3B-instruct-v1.5-bf16"
    )
```
7. Запустить inference baseline из корневой директории репозитория:
```
cd src && python run.py
```

## Данные
### Входные данные
Для Конкурса был разработан датасет, предназначенный для оценки способности языковых моделей к долговременному запоминанию в условиях многосессионного взаимодействия. Он включает диалоги между пользователем и ассистентом.

Цель — проверить, насколько качественно модуль памяти запоминает и извлекает информацию из длинных диалогов. Для этого в сете предусмотрены вопросы по истории диалога. В среднем каждый диалог состоит из нескольких десятков сессий разной длины и содержит примерно 300 тысяч символов (или около 100 тысяч токенов).

Полный набор данных для оценки недоступен Участникам. Участникам предоставляется [пример формата данных](https://gitverse.ru/ai-forever/memory_aij2025/content/main/data/format_example.jsonl), который содержит 4 уникальные записи.

### Описание датасета

Каждая запись представляет собой набор из: 
1) уникального идентификатора — `id`;
2) вопроса — `question`;
3) типа вопроса — `question_type`;
4) ответа — `ans`;
5) набора сессий — `sessions`;
6) указаний на айди сессий с ответом — `ans_session_ids`.

#### Диалог
Каждый диалог состоит из списка сессий (обычно это несколько десятков сессий).

#### Сессия
Каждая сессия имеет свой уникальный идентификатор `id` и состоит из списка реплик пользователя `user` и системы `assistant`.

#### Реплика
Реплика имеет вид `{"role": "роль", "content": "сообщение"}`.

#### Пример из датасета
В каждой строке jsonl-файла содержится конструкция следующего вида:
```
{
    "id": "1",
    "question": "Как меня зовут?",
    "question_type": "fact_equal_session"
    "ans": "Иван",
    "sessions": [
        {
            "id": "session_id1",
            "messages": [
                {"role": "user", "content": "Привет, меня зовут Иван."},
                {"role": "assistant", "content": "Привет, приятно познакомиться, Иван!"}
            ]
        },
        {
            "id": "session_id2",
            "messages": [
                {"role": "user", "content": "У меня есть кот по имени Барсик."},
                {"role": "assistant", "content": "Как интересно! А сколько ему лет?"},
                {"role": "user", "content": "Ему 2."},
                {"role": "assistant", "content": "Ой, так он же совсем котёнок."}
            ]
        },
        {
            "id": "session_id3",
            "messages": [
                {"role": "user", "content": "Моя собака Лайка обожает мою девушку."},
                {"role": "assistant", "content": "Замечательно, когда твои питомцы любят близких тебе людей!"},
                {"role": "user", "content": "А вот мой кот, наоборот, её боится."},
                {"role": "assistant", "Коты в целом менее социальные животные, так что не стоит сильно переживать по этому поводу."}
            ]
        },
        {
            "id": "session_id4",
            "messages": [
                {"role": "user", "content": "Помнишь, я говорил про свою девушку?"},
                {"role": "assistant", "content": "Помню. Твоя собака очень её любит."},
                {"role": "user", "content": "Так вот, теперь она не моя девушка, а моя жена."},
                {"role": "assistant", "Ты женился? Поздравляю!"}
            ]
        }
    ],
    "ans_session_ids": ["session_id1"]
}
```

#### Вопросы
Вопросы бывают четырёх типов:
| Тип вопроса | Описание | Пример |
|-|-|-|
| fact_equal_session | Ответ на вопрос содержится в одной конкретной сессии. | Как меня зовут? (Ответ содержится в session_id1) |
| info_consolidation | Ответ на вопрос содержится в нескольких сессиях. Чтобы найти ответ, нужно сагрегировать информацию из разных частей диалога. | Какие домашние животные у меня есть? (Ответ на основе session_id2 и session_id3) |
| info_updating | Для этого типа характерно, что информация о пользователе меняется на протяжении диалога. | Я женат? (Ответ на основе session_id3 и session_id4, в четвёртой сессии информация обновляется) |
| no_info | Вопросы, на которые нет ответа в диалоге. | Сколько мне лет? (Ответа в диалоге нет)|


#### Специфика диалогов
* Пользователь может писать как короткие диалоговые фразы, так и длинные запросы, например: «перескажи статью…» или «переведи текст…».
* Не во всех сессиях присутствует информация о пользователе.
* Состав сета: часть диалогов взята из логов общения пользователей с GigaChat (персональные данные были обезличены), а часть сгенерирована двумя моделями: одна выполняла роль юзера, вторая — роль ассистента. Некоторые диалоги генерировались зарубежными языковыми моделями, поэтому в них могут присутствовать явления и объекты, характерные для западного общества.
* Вопросы задаются к любой сессии, а не только к первой или последней.



### Выходные данные
После успешного inference у вас должен появиться файл `submit.csv`, который будет использоваться на этапе получения итоговой оценки решения. Множество уникальных идентификаторов во входных и выходных данных должно совпадать. 

Выходной файл представляет собой таблицу с сигнатурой:

| id | answer | answer_time |
|-|-|-|
| 1 | Тебя зовут Василий. | 1.3924849033355713 |
| 2 | У тебя двое детей. | 0.7695510387420654 |

- **id** — уникальный идентификатор, который соответствует запросу во входных данных;
- **answer** — ответ модели на вопрос по памяти из диалога;
- **answer_time** — время, которое потребовалось на ответ на вопрос, в секундах.


## Подсчёт метрики
- Тип метрики: Accuracy
- Смысл: Доля совпадающих ответов. Ответ совпадает, если он семантически (по смыслу) идентичен верному
- Техника сравнения: LLM as a judge

На вход скрипту оценки подаётся файл `submit.csv` со сгенерированными моделью ответами на тестовые вопросы и файл с правильными ответами. Каждая пара ответов поступает на вход LLM, которая, используя развёрнутые инструкции, оценивает, насколько ответ сабмита похож на верный ответ на заданный вопрос, и выдаёт бинарный вердикт. При неудачной попытке получить вердикт процесс повторяется k раз, пока не удастся его получить, после k раз вердикт будет отрицательным. Параметры генерации LLM зафиксированы таким образом, чтобы минимизировать вариативность вердикта, и, следовательно, финальной оценки от запуска к запуску.

Важно!
Старайтесь, чтобы ответы в вашем сабмите были короткими и информативными, не более 1 предложения.

Не стоит пытаться в своих ответах “обмануть” судью. Попытки prompt injection, хитрых формулировок и т.д. отслеживаются, и при попадании подобного сабмита в топ лидерборда он будет исключён.

## Ограничения
В течение одних суток Участник или Команда Участников может загрузить для оценки не более 3 (трёх) решений. Учитываются только валидные попытки, получившие численную оценку. Если при расчёте метрики возникло исключение, решение считается невалидным, и счётчик попыток не уменьшается.

Контейнер с решением запускается в следующих условиях:

* 243 Гб RAM
* 16 CPU-cores
* 1 GPU Tesla A100 (80 Гб)
* 10 Гб дискового пространства 
* Максимальное время на выполнение решения: 8 часов, из них 7 часов на генерацию ответов на вопросы и 1 час на оценку ответов с помощью «LLM as a judge»
* Окружение, в котором запускается решение, не имеет доступ к ресурсам Интернета
* Ограничение на суммарный вес загружаемого решения: 5 Гб

## Baseline решение
В качестве базового решения Участникам будет предложена реализация, которая накапливает весь контекст диалога на стадии запоминания. После чего на стадии ответа на вопрос весь диалог подаётся на вход модели вместе с тестовым вопросом. В случае, когда длина диалога превышает максимальную длину контекста, которую поддерживает модель, вопрос последовательно задаётся только к последним фразам, помещающимся в контекст.

## Призовой фонд
* Первое место – 900 000 рублей    
* Второе место – 700 000 рублей     
* Третье место – 400 000 рублей   

