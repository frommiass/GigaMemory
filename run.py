#!/usr/bin/env python
"""
–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã GigaMemory
"""
import argparse
import json
import sys
from pathlib import Path
from typing import List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent / "src"))

def load_dialogue(file_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∏–∞–ª–æ–≥ –∏–∑ —Ñ–∞–π–ª–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def process_dialogue(dialogue: Dict[str, Any], model_path: str = None) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ª–æ–≥ —Å –ø–æ–º–æ—â—å—é —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏"""
    try:
        from submit.model_inference import SubmitModelWithMemory
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é
        system = SubmitModelWithMemory(model_path or "mock_model")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Å—Å–∏–∏
        dialogue_id = dialogue["id"]
        total_messages = 0
        filtered_messages = 0
        
        for session in dialogue["sessions"]:
            messages = []
            for msg_data in session["messages"]:
                from models import Message
                message = Message(
                    role=msg_data["role"],
                    content=msg_data["content"],
                    session_id=session["id"]
                )
                messages.append(message)
                total_messages += 1
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ø–∞–º—è—Ç—å
            system.write_to_memory(messages, dialogue_id)
            filtered_messages += len(messages)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = system.get_stats()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
        question = dialogue.get("question", "–ö–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç?")
        answer = system.answer_to_question(dialogue_id, question)
        
        return {
            "dialogue_id": dialogue_id,
            "question": question,
            "answer": answer,
            "stats": stats,
            "total_messages": total_messages,
            "filtered_messages": filtered_messages
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∏–∞–ª–æ–≥–∞: {e}")
        import traceback
        traceback.print_exc()
        return {
            "dialogue_id": dialogue["id"],
            "error": str(e)
        }


def run_test():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç —Å –±–æ–ª—å—à–∏–º –¥–∏–∞–ª–æ–≥–æ–º"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ —Å–∏—Å—Ç–µ–º—ã GigaMemory —Å –±–æ–ª—å—à–∏–º –¥–∏–∞–ª–æ–≥–æ–º")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
    test_file = Path("test_dialogue_100k.jsonl")
    if not test_file.exists():
        print("‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python validate_system.py")
        return 1
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∏–∞–ª–æ–≥
    print("üìñ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∏–∞–ª–æ–≥...")
    dialogue = load_dialogue(str(test_file))
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –¥–∏–∞–ª–æ–≥: {dialogue['id']} —Å {len(dialogue['sessions'])} —Å–µ—Å—Å–∏—è–º–∏")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥
    print("‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥...")
    result = process_dialogue(dialogue)
    
    if "error" in result:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
        return 1
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"–î–∏–∞–ª–æ–≥ ID: {result['dialogue_id']}")
    print(f"–í–æ–ø—Ä–æ—Å: {result['question']}")
    print(f"–û—Ç–≤–µ—Ç: {result['answer']}")
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"  –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {result['total_messages']}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {result['filtered_messages']}")
    print(f"  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∫–æ–ø–∏–ø–∞—Å—Ç–∞: {result['stats'].get('copypaste_filtered', 0)}")
    print(f"  –°–æ–∑–¥–∞–Ω–æ —Å–µ—Å—Å–∏–π: {result['stats'].get('sessions_created', 0)}")
    print(f"  –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {result['stats'].get('facts_extracted', 0)}")
    print(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {result['stats'].get('compression_ratio', 1.0):.2f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = Path("test_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    
    return 0


def run_inference(dataset_path: str, output_path: str, model_path: str):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ: {dataset_path}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    output_dir = Path(output_path)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dialogues = []
    with open(dataset_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                dialogues.append(json.loads(line))
    
    print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dialogues)} –¥–∏–∞–ª–æ–≥–æ–≤")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –¥–∏–∞–ª–æ–≥
    results = []
    for i, dialogue in enumerate(dialogues):
        print(f"‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥ {i+1}/{len(dialogues)}: {dialogue.get('id', 'unknown')}")
        result = process_dialogue(dialogue, model_path)
        results.append(result)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = output_dir / "results.jsonl"
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    print("‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    
    return 0


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="GigaMemory System Runner")
    parser.add_argument("--test", action="store_true", help="–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç —Å –±–æ–ª—å—à–∏–º –¥–∏–∞–ª–æ–≥–æ–º")
    parser.add_argument("--dataset", type=str, help="–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    parser.add_argument("--output", type=str, default="./output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--model", type=str, default="/app/models/GigaChat-20B-A3B-instruct-v1.5-bf16", help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏")
    
    args = parser.parse_args()
    
    if args.test:
        return run_test()
    elif args.dataset:
        return run_inference(args.dataset, args.output, args.model)
    else:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ --test –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–ª–∏ --dataset –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
        parser.print_help()
        return 1


if __name__ == "__main__":
    sys.exit(main())
