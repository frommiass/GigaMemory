#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ RAG –≤ GigaMemory
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –∑–∞–º–µ–Ω–∏—Ç—å –æ–±—ã—á–Ω—ã–π RAG –Ω–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from models import Message
from src.submit.model_inference_vector import SubmitModelWithVectorMemory


def example_basic_integration():
    """–ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    print("üöÄ –ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ RAG")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º RAG
    model = SubmitModelWithVectorMemory(
        model_path="path/to/your/model",  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –ø—É—Ç—å
        use_vector_rag=True,
        vector_model="cointegrated/rubert-tiny2",
        use_gpu=True,
        enable_hybrid_search=True
    )
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º RAG —Å–æ–∑–¥–∞–Ω–∞")
    
    # –ü—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞
    dialogue_id = "example_dialogue"
    messages = [
        Message(role="user", content="–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π, —è –∏–∑ –ú–æ—Å–∫–≤—ã."),
        Message(role="assistant", content="–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –ê–ª–µ–∫—Å–µ–π! –†–∞–¥ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è."),
        Message(role="user", content="–Ø —Ä–∞–±–æ—Ç–∞—é –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º –≤ –Ø–Ω–¥–µ–∫—Å–µ."),
        Message(role="assistant", content="–û—Ç–ª–∏—á–Ω–æ! –Ø–Ω–¥–µ–∫—Å - –∫—Ä—É–ø–Ω–∞—è IT-–∫–æ–º–ø–∞–Ω–∏—è."),
        Message(role="user", content="–£ –º–µ–Ω—è –µ—Å—Ç—å –∫–æ—Ç –ø–æ –∏–º–µ–Ω–∏ –ë–∞—Ä—Å–∏–∫."),
        Message(role="assistant", content="–ë–∞—Ä—Å–∏–∫ - –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ –∏–º—è –¥–ª—è –∫–æ—Ç–∞!"),
    ]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è)
    print("\nüìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø–∞–º—è—Ç—å...")
    model.write_to_memory(messages, dialogue_id)
    print("‚úÖ –°–æ–æ–±—â–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–ö–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç?",
        "–ì–¥–µ —è —Ä–∞–±–æ—Ç–∞—é?",
        "–ö–∞–∫ –∑–æ–≤—É—Ç –º–æ–µ–≥–æ –∫–æ—Ç–∞?",
        "–û—Ç–∫—É–¥–∞ —è?"
    ]
    
    print("\n‚ùì –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤:")
    for question in test_questions:
        print(f"\n–í–æ–ø—Ä–æ—Å: {question}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        search_results = model.get_vector_search_results(question, dialogue_id, top_k=3)
        
        if search_results:
            print("üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
            for i, result in enumerate(search_results, 1):
                print(f"  {i}. Score: {result['score']:.3f}")
                print(f"     Text: {result['text'][:100]}...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)
        # answer = model.answer_to_question(dialogue_id, question)
        # print(f"–û—Ç–≤–µ—Ç: {answer}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ RAG:")
    stats = model.get_vector_rag_stats()
    print(f"  –í–µ–∫—Ç–æ—Ä–Ω—ã–π RAG –≤–∫–ª—é—á–µ–Ω: {stats.get('vector_rag_enabled', False)}")
    print(f"  –í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats.get('total_dialogues', 0)}")
    print(f"  –í—Å–µ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â: {stats.get('total_stores', 0)}")
    
    if 'embedding_stats' in stats:
        emb_stats = stats['embedding_stats']
        print(f"  –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {emb_stats.get('total_encoded', 0)}")
        print(f"  Cache hit rate: {emb_stats.get('cache_hit_rate', 0):.1%}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...")
    model.save_vector_indices("./example_vector_indices")
    print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    
    return model


def example_advanced_integration():
    """–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    print("\nüîß –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    model = SubmitModelWithVectorMemory(
        model_path="path/to/your/model",
        use_vector_rag=True,
        vector_model="cointegrated/LaBSE-en-ru",  # –ë–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        use_gpu=True,
        enable_hybrid_search=True
    )
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å–æ–∑–¥–∞–Ω–∞")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...")
    model.load_vector_indices("./example_vector_indices")
    print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    dialogue_id = "example_dialogue"
    question = "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–±–æ—Ç–µ –∏ –ø–∏—Ç–æ–º—Ü–∞—Ö"
    
    print(f"\nüîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: '{question}'")
    results = model.get_vector_search_results(question, dialogue_id, top_k=5)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.3f}")
        print(f"   –¢–µ–∫—Å—Ç: {result['text']}")
        print(f"   –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result['metadata']}")
    
    return model


def example_comparison():
    """–ü—Ä–∏–º–µ—Ä —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ RAG"""
    print("\n‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ RAG")
    print("=" * 50)
    
    # –ú–æ–¥–µ–ª—å —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º RAG
    vector_model = SubmitModelWithVectorMemory(
        model_path="path/to/your/model",
        use_vector_rag=True,
        vector_model="cointegrated/rubert-tiny2"
    )
    
    # –ú–æ–¥–µ–ª—å —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º RAG
    traditional_model = SubmitModelWithVectorMemory(
        model_path="path/to/your/model",
        use_vector_rag=False
    )
    
    print("‚úÖ –°–æ–∑–¥–∞–Ω—ã –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    dialogue_id = "comparison_test"
    messages = [
        Message(role="user", content="–ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è, —è –≤—Ä–∞—á-–∫–∞—Ä–¥–∏–æ–ª–æ–≥."),
        Message(role="assistant", content="–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –ú–∞—Ä–∏—è! –ö–∞—Ä–¥–∏–æ–ª–æ–≥–∏—è - –≤–∞–∂–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –º–µ–¥–∏—Ü–∏–Ω—ã."),
        Message(role="user", content="–Ø —Ä–∞–±–æ—Ç–∞—é –≤ –±–æ–ª—å–Ω–∏—Ü–µ –∏–º–µ–Ω–∏ –ë–æ—Ç–∫–∏–Ω–∞."),
        Message(role="assistant", content="–ë–æ–ª—å–Ω–∏—Ü–∞ –ë–æ—Ç–∫–∏–Ω–∞ - –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ."),
        Message(role="user", content="–£ –º–µ–Ω—è –µ—Å—Ç—å –¥–æ—á—å –ê–Ω–Ω–∞, –µ–π 8 –ª–µ—Ç."),
        Message(role="assistant", content="–ê–Ω–Ω–∞ - –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ –∏–º—è –¥–ª—è –¥–æ—á–µ—Ä–∏!"),
    ]
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    print("\nüìù –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    vector_model.write_to_memory(messages, dialogue_id)
    traditional_model.write_to_memory(messages, dialogue_id)
    print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–ö–∞–∫ –∑–æ–≤—É—Ç –≤—Ä–∞—á–∞?",
        "–ì–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ú–∞—Ä–∏—è?",
        "–ö–∞–∫ –∑–æ–≤—É—Ç –¥–æ—á—å?",
        "–°–∫–æ–ª—å–∫–æ –ª–µ—Ç –¥–æ—á–µ—Ä–∏?"
    ]
    
    print("\n‚ùì –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for question in test_questions:
        print(f"\n–í–æ–ø—Ä–æ—Å: {question}")
        
        # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        vector_results = vector_model.get_vector_search_results(question, dialogue_id, top_k=2)
        print("üîç –í–µ–∫—Ç–æ—Ä–Ω—ã–π RAG:")
        for result in vector_results:
            print(f"  Score: {result['score']:.3f} - {result['text'][:60]}...")
        
        # –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π RAG (—Å–∏–º—É–ª—è—Ü–∏—è)
        print("üìö –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π RAG:")
        print("  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç keyword matching –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é")
        print("  –ú–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞")


def example_migration_guide():
    """–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏ —Å –æ–±—ã—á–Ω–æ–≥–æ RAG –Ω–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π"""
    print("\nüìã –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏")
    print("=" * 50)
    
    migration_code = '''
# ============== –ú–ò–ì–†–ê–¶–ò–Ø –° –û–ë–´–ß–ù–û–ì–û RAG –ù–ê –í–ï–ö–¢–û–†–ù–´–ô ==============

# –ë–´–õ–û (–≤ src/submit/model_inference.py):
from .rag.engine import RAGEngine

class SubmitModelWithMemory(ModelWithMemory):
    def __init__(self, model_path: str) -> None:
        self.storage = MemoryStorage()
        self.model_inference = ModelInference(model_path)
        self.rag_interface = RAGEngine()  # –û–±—ã—á–Ω—ã–π RAG

# –°–¢–ê–õ–û (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞):
from .rag.vector_rag_interface import VectorRAGInterface

class SubmitModelWithMemory(ModelWithMemory):
    def __init__(self, model_path: str) -> None:
        self.storage = MemoryStorage()
        self.model_inference = ModelInference(model_path)
        self.rag_interface = VectorRAGInterface(  # –í–µ–∫—Ç–æ—Ä–Ω—ã–π RAG
            model_name="cointegrated/rubert-tiny2",
            use_gpu=True,
            enable_hybrid_search=True
        )

# ============== –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ô –°–ü–û–°–û–ë ==============

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ—Ç–æ–≤—ã–π –∫–ª–∞—Å—Å:
from .model_inference_vector import SubmitModelWithVectorMemory

# –ü—Ä–æ—Å—Ç–æ –∑–∞–º–µ–Ω–∏—Ç–µ –∫–ª–∞—Å—Å:
class SubmitModelWithMemory(SubmitModelWithVectorMemory):
    def __init__(self, model_path: str) -> None:
        super().__init__(
            model_path=model_path,
            use_vector_rag=True,  # –í–∫–ª—é—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π RAG
            vector_model="cointegrated/rubert-tiny2",
            use_gpu=True,
            enable_hybrid_search=True
        )

# ============== –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò ==============

# –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö:
config = VectorRAGConfig(
    embedding_batch_size=64,      # –ë–æ–ª—å—à–µ –±–∞—Ç—á = –±—ã—Å—Ç—Ä–µ–µ
    use_amp=True,                # Mixed precision –Ω–∞ GPU
    compile_model=True,          # torch.compile (PyTorch 2.0+)
    optimize_on_save=True       # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
)

# ============== –ú–û–ù–ò–¢–û–†–ò–ù–ì ==============

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:
stats = model.get_vector_rag_stats()
print(f"Cache hit rate: {stats['embedding_stats']['cache_hit_rate']:.1%}")
print(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats['total_dialogues']}")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤:
model.save_vector_indices("./my_indices")
model.load_vector_indices("./my_indices")
'''
    
    print(migration_code)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
    print("üéØ –ü–†–ò–ú–ï–†–´ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –í–ï–ö–¢–û–†–ù–û–ì–û RAG –í GIGAMEMORY")
    print("=" * 60)
    
    try:
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä
        example_basic_integration()
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–∏–º–µ—Ä
        example_advanced_integration()
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        example_comparison()
        
        # –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏
        example_migration_guide()
        
        print("\nüéâ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("VectorRAGInterface –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ –≤–∞—à–µ–º –ø—Ä–æ–µ–∫—Ç–µ!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
